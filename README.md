# ğŸ¤– AI Agent

A real-time AI assistant that searches the web to answer questions, built with **LangGraph**, **Groq (LLaMA 3.3 70B)**, and **FastAPI**, with a **Streamlit** chat frontend.

---

## âœ¨ Features

- ğŸ’¬ ChatGPT-style chat interface
- ğŸ” Real-time web search via DuckDuckGo
- ğŸ§  Per-session conversation memory
- âš¡ Fast inference using Groq's LLaMA 3.3 70B model
- ğŸ”— REST API backend (FastAPI) + interactive UI (Streamlit)

---

## ğŸ—ï¸ Architecture

```
User (Streamlit UI)
        â†“  HTTP POST /chat
FastAPI Backend (uvicorn)
        â†“
LangGraph ReAct Agent
        â†“              â†“
  Groq LLM       DuckDuckGo Search
  (LLaMA 3.3)     (web_search tool)
```

---

## ğŸ“ Project Structure

```
AI-Agent/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ agent/
â”‚       â”œâ”€â”€ agent.py      # LangGraph ReAct agent + Groq LLM
â”‚       â”œâ”€â”€ main.py       # FastAPI app & endpoints
â”‚       â”œâ”€â”€ memory.py     # Conversation memory
â”‚       â””â”€â”€ tools.py      # DuckDuckGo web search tool
â”œâ”€â”€ frontend.py           # Streamlit chat UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  # API keys (not committed)
â””â”€â”€ .gitignore
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/g-akshaya/AI-AGENT.git
cd AI-AGENT
```

### 2. Create a virtual environment

```bash
python -m venv .venv
.venv\Scripts\activate       # Windows
# source .venv/bin/activate  # macOS/Linux
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up environment variables

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your_groq_api_key_here
```

Get a free API key at [console.groq.com](https://console.groq.com).

---

## â–¶ï¸ Running the App

You need **two terminals** â€” one for the backend, one for the frontend.

### Terminal 1 â€” FastAPI backend

```bash
python -m uvicorn app.agent.main:app --reload
```

Backend runs at `http://127.0.0.1:8000`

### Terminal 2 â€” Streamlit frontend

```bash
streamlit run frontend.py
```

Frontend runs at `http://localhost:8501`

---

## ğŸ”Œ API Reference

### `GET /health`
Returns server status.

```json
{ "status": "ok" }
```

### `POST /chat`
Send a message to the agent.

**Request:**
```json
{
  "query": "What happened in the news today?",
  "session_id": "user-123"
}
```

**Response:**
```json
{
  "response": "...",
  "session_id": "user-123"
}
```

Interactive docs available at `http://127.0.0.1:8000/docs`.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| LLM | Groq â€” LLaMA 3.3 70B Versatile |
| Agent framework | LangGraph (ReAct agent) |
| Web search | DuckDuckGo (`langchain-community`) |
| Backend | FastAPI + Uvicorn |
| Frontend | Streamlit |
| Memory | LangGraph `MemorySaver` (in-memory, per session) |
